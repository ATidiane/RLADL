{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import gym\n",
    "from gym import wrappers, logger\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from a2c import A2C, A2CBatch\n",
    "from main import  init_environment, run_agent_on_environment\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "# matplotlib.use(\"TkAgg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Online A2C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CartPole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of 10 last rewards for episode 10 : 11.090909090909092 (std 4.273694281288421)\n",
      "Mean of 10 last rewards for episode 20 : 9.090909090909092 (std 2.9681504940571832)\n",
      "Mean of 10 last rewards for episode 30 : 8.909090909090908 (std 3.0287874998104876)\n",
      "Mean of 10 last rewards for episode 40 : 8.909090909090908 (std 2.906248611481051)\n",
      "Mean of 10 last rewards for episode 50 : 8.818181818181818 (std 3.009626428590336)\n",
      "Mean of 10 last rewards for episode 60 : 8.454545454545455 (std 2.9034035313947837)\n",
      "Mean of 10 last rewards for episode 70 : 8.363636363636363 (std 2.7723546694503463)\n",
      "Mean of 10 last rewards for episode 80 : 8.636363636363637 (std 2.8049542946439114)\n",
      "Mean of 10 last rewards for episode 90 : 8.818181818181818 (std 2.9485954073139733)\n",
      "Mean of 10 last rewards for episode 100 : 8.272727272727273 (std 2.699862255439545)\n",
      "Mean of 10 last rewards for episode 110 : 8.454545454545455 (std 2.7090298955911525)\n",
      "Mean of 10 last rewards for episode 120 : 8.636363636363637 (std 2.8049542946439114)\n",
      "Mean of 10 last rewards for episode 130 : 8.0 (std 2.6628760937957834)\n",
      "Mean of 10 last rewards for episode 140 : 8.727272727272727 (std 2.7990553306073913)\n",
      "Mean of 10 last rewards for episode 150 : 8.0 (std 2.6285149626910838)\n",
      "Mean of 10 last rewards for episode 160 : 8.545454545454545 (std 2.7753340949952268)\n",
      "Mean of 10 last rewards for episode 170 : 8.454545454545455 (std 2.74238238709061)\n",
      "Mean of 10 last rewards for episode 180 : 8.181818181818182 (std 2.6566616720368104)\n",
      "Mean of 10 last rewards for episode 190 : 8.272727272727273 (std 2.73332661424962)\n",
      "Mean of 10 last rewards for episode 200 : 8.909090909090908 (std 2.8747978728803445)\n",
      "Mean of 10 last rewards for episode 210 : 8.272727272727273 (std 2.699862255439545)\n",
      "Mean of 10 last rewards for episode 220 : 8.545454545454545 (std 2.7753340949952268)\n",
      "Mean of 10 last rewards for episode 230 : 9.0 (std 2.860387767736777)\n",
      "Mean of 10 last rewards for episode 240 : 8.636363636363637 (std 2.8049542946439114)\n",
      "Mean of 10 last rewards for episode 250 : 8.454545454545455 (std 2.7753340949952268)\n",
      "Mean of 10 last rewards for episode 260 : 8.454545454545455 (std 2.74238238709061)\n",
      "Mean of 10 last rewards for episode 270 : 8.636363636363637 (std 2.8049542946439114)\n",
      "Mean of 10 last rewards for episode 280 : 8.545454545454545 (std 2.807899129360091)\n",
      "Mean of 10 last rewards for episode 290 : 8.545454545454545 (std 2.807899129360091)\n",
      "Mean of 10 last rewards for episode 300 : 8.454545454545455 (std 2.74238238709061)\n",
      "Mean of 10 last rewards for episode 310 : 8.272727272727273 (std 2.699862255439545)\n",
      "Mean of 10 last rewards for episode 320 : 8.727272727272727 (std 2.7990553306073913)\n",
      "Mean of 10 last rewards for episode 330 : 8.545454545454545 (std 2.807899129360091)\n",
      "Mean of 10 last rewards for episode 340 : 8.545454545454545 (std 2.74238238709061)\n",
      "Mean of 10 last rewards for episode 350 : 8.181818181818182 (std 2.690663379445226)\n",
      "Mean of 10 last rewards for episode 360 : 8.090909090909092 (std 2.6783490659374976)\n",
      "Mean of 10 last rewards for episode 370 : 8.454545454545455 (std 2.7090298955911525)\n",
      "Mean of 10 last rewards for episode 380 : 8.545454545454545 (std 2.74238238709061)\n",
      "Mean of 10 last rewards for episode 390 : 8.454545454545455 (std 2.74238238709061)\n",
      "Mean of 10 last rewards for episode 400 : 8.454545454545455 (std 2.74238238709061)\n",
      "Mean of 10 last rewards for episode 410 : 8.181818181818182 (std 2.622219109428356)\n",
      "Mean of 10 last rewards for episode 420 : 8.545454545454545 (std 2.8400907912387834)\n",
      "Mean of 10 last rewards for episode 430 : 8.636363636363637 (std 2.7723546694503467)\n",
      "Mean of 10 last rewards for episode 440 : 8.272727272727273 (std 2.73332661424962)\n",
      "Mean of 10 last rewards for episode 450 : 8.363636363636363 (std 2.739367122421702)\n",
      "Mean of 10 last rewards for episode 460 : 8.636363636363637 (std 2.8049542946439114)\n",
      "Mean of 10 last rewards for episode 470 : 9.090909090909092 (std 2.906248611481051)\n",
      "Mean of 10 last rewards for episode 480 : 8.272727272727273 (std 2.699862255439545)\n",
      "Mean of 10 last rewards for episode 490 : 8.363636363636363 (std 2.705977466570403)\n",
      "Mean of 10 last rewards for episode 500 : 8.454545454545455 (std 2.74238238709061)\n",
      "Mean of 10 last rewards for episode 510 : 8.636363636363637 (std 2.8049542946439114)\n",
      "Mean of 10 last rewards for episode 520 : 8.818181818181818 (std 2.8225772175018222)\n",
      "Mean of 10 last rewards for episode 530 : 8.909090909090908 (std 2.906248611481051)\n",
      "Mean of 10 last rewards for episode 540 : 8.090909090909092 (std 2.644189013136179)\n",
      "Mean of 10 last rewards for episode 550 : 8.636363636363637 (std 2.8049542946439114)\n",
      "Mean of 10 last rewards for episode 560 : 8.272727272727273 (std 2.699862255439545)\n",
      "Mean of 10 last rewards for episode 570 : 8.727272727272727 (std 2.7990553306073913)\n",
      "Mean of 10 last rewards for episode 580 : 8.545454545454545 (std 2.74238238709061)\n",
      "Mean of 10 last rewards for episode 590 : 8.181818181818182 (std 2.6566616720368104)\n",
      "Mean of 10 last rewards for episode 600 : 8.545454545454545 (std 2.7753340949952268)\n",
      "Mean of 10 last rewards for episode 610 : 8.727272727272727 (std 2.7990553306073913)\n",
      "Mean of 10 last rewards for episode 620 : 8.636363636363637 (std 2.7723546694503467)\n",
      "Mean of 10 last rewards for episode 630 : 8.181818181818182 (std 2.6566616720368104)\n",
      "Mean of 10 last rewards for episode 640 : 8.727272727272727 (std 2.86327559054975)\n",
      "Mean of 10 last rewards for episode 650 : 8.545454545454545 (std 2.8719216361693296)\n",
      "Mean of 10 last rewards for episode 660 : 8.363636363636363 (std 2.705977466570403)\n",
      "Mean of 10 last rewards for episode 670 : 8.454545454545455 (std 2.74238238709061)\n",
      "Mean of 10 last rewards for episode 680 : 8.363636363636363 (std 2.705977466570403)\n",
      "Mean of 10 last rewards for episode 690 : 8.636363636363637 (std 2.8049542946439114)\n",
      "Mean of 10 last rewards for episode 700 : 8.909090909090908 (std 2.8429992311112526)\n",
      "Mean of 10 last rewards for episode 710 : 8.181818181818182 (std 2.690663379445226)\n",
      "Mean of 10 last rewards for episode 720 : 8.363636363636363 (std 2.804954294643911)\n",
      "Mean of 10 last rewards for episode 730 : 8.363636363636363 (std 2.705977466570403)\n",
      "Mean of 10 last rewards for episode 740 : 8.636363636363637 (std 2.8049542946439114)\n",
      "Mean of 10 last rewards for episode 750 : 8.181818181818182 (std 2.690663379445226)\n",
      "Mean of 10 last rewards for episode 760 : 8.636363636363637 (std 2.7723546694503467)\n",
      "Mean of 10 last rewards for episode 770 : 8.454545454545455 (std 2.74238238709061)\n",
      "Mean of 10 last rewards for episode 780 : 8.454545454545455 (std 2.8400907912387834)\n",
      "Mean of 10 last rewards for episode 790 : 8.636363636363637 (std 2.8049542946439114)\n",
      "Mean of 10 last rewards for episode 800 : 8.727272727272727 (std 2.7990553306073913)\n",
      "Mean of 10 last rewards for episode 810 : 8.454545454545455 (std 2.7753340949952268)\n",
      "Mean of 10 last rewards for episode 820 : 8.454545454545455 (std 2.74238238709061)\n",
      "Mean of 10 last rewards for episode 830 : 8.181818181818182 (std 2.6566616720368104)\n",
      "Mean of 10 last rewards for episode 840 : 8.636363636363637 (std 2.7723546694503467)\n",
      "Mean of 10 last rewards for episode 850 : 8.454545454545455 (std 2.7753340949952268)\n",
      "Mean of 10 last rewards for episode 860 : 8.545454545454545 (std 2.74238238709061)\n",
      "Mean of 10 last rewards for episode 870 : 8.363636363636363 (std 2.705977466570403)\n",
      "Mean of 10 last rewards for episode 880 : 8.545454545454545 (std 2.7753340949952268)\n",
      "Mean of 10 last rewards for episode 890 : 8.363636363636363 (std 2.7723546694503463)\n",
      "Mean of 10 last rewards for episode 900 : 8.727272727272727 (std 2.831347545890443)\n",
      "Mean of 10 last rewards for episode 910 : 8.454545454545455 (std 2.74238238709061)\n",
      "Mean of 10 last rewards for episode 920 : 8.727272727272727 (std 2.7990553306073913)\n",
      "Mean of 10 last rewards for episode 930 : 8.363636363636363 (std 2.739367122421702)\n",
      "Mean of 10 last rewards for episode 940 : 8.454545454545455 (std 2.7753340949952268)\n",
      "Mean of 10 last rewards for episode 950 : 8.909090909090908 (std 2.8747978728803445)\n",
      "Mean of 10 last rewards for episode 960 : 8.363636363636363 (std 2.705977466570403)\n",
      "Mean of 10 last rewards for episode 970 : 8.363636363636363 (std 2.739367122421702)\n",
      "Mean of 10 last rewards for episode 980 : 8.363636363636363 (std 2.705977466570403)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of 10 last rewards for episode 990 : 8.363636363636363 (std 2.739367122421702)\n",
      "Mean of 10 last rewards for episode 1000 : 8.363636363636363 (std 2.67217062849074)\n"
     ]
    }
   ],
   "source": [
    "# Initialisation de l'environnement\n",
    "env_id = 'CartPole-v1'\n",
    "env, envx = init_environment(env_id, seed=0)\n",
    "\n",
    "agent = A2C(dim_input=env.observation_space.shape[0],\n",
    "            dim_output=env.action_space.n,\n",
    "            gamma=0.99,\n",
    "            alpha=0.7,\n",
    "            layers=[200],\n",
    "            lr_V=0.001,\n",
    "            lr_pi=0.001)\n",
    "run_agent_on_environment(agent, env, envx,\n",
    "                         max_episode=1000,\n",
    "                         iter_print=10,\n",
    "                         iter_show=100, name_file='a2c_cartpole.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of 10 last rewards for episode 10 : -209.4925405328924 (std 142.0468293652938)\n",
      "Mean of 10 last rewards for episode 20 : -111.38636467673562 (std 101.50882526912838)\n",
      "Mean of 10 last rewards for episode 30 : -119.04245966131037 (std 41.70649174933107)\n",
      "Mean of 10 last rewards for episode 40 : -101.08793293346058 (std 61.345528835104695)\n",
      "Mean of 10 last rewards for episode 50 : -118.52248937433416 (std 43.6990999237616)\n",
      "Mean of 10 last rewards for episode 60 : -152.61209938742897 (std 67.14826808628662)\n",
      "Mean of 10 last rewards for episode 70 : -121.34483268044211 (std 49.07001925461506)\n",
      "Mean of 10 last rewards for episode 80 : -148.31348765980113 (std 64.68029554130692)\n",
      "Mean of 10 last rewards for episode 90 : -90.35026411576705 (std 58.337197854243605)\n",
      "Mean of 10 last rewards for episode 100 : -129.2414190118963 (std 51.13575810151807)\n",
      "Mean of 10 last rewards for episode 110 : -144.3570660677823 (std 104.30813203307079)\n",
      "Mean of 10 last rewards for episode 120 : -144.83329010009766 (std 98.16263934438241)\n",
      "Mean of 10 last rewards for episode 130 : -115.18451066450639 (std 48.81409023753487)\n",
      "Mean of 10 last rewards for episode 140 : -118.39310524680398 (std 43.914988012781315)\n",
      "Mean of 10 last rewards for episode 150 : -106.02868444269353 (std 40.21356251046176)\n",
      "Mean of 10 last rewards for episode 160 : -121.80116202614524 (std 69.68236580480927)\n",
      "Mean of 10 last rewards for episode 170 : -161.895788712935 (std 80.17045645245429)\n",
      "Mean of 10 last rewards for episode 180 : -404.99899846857244 (std 192.94885026942134)\n",
      "Mean of 10 last rewards for episode 190 : -428.4345002607866 (std 232.96314501202187)\n",
      "Mean of 10 last rewards for episode 200 : -294.1269933527166 (std 270.26694515921724)\n",
      "Mean of 10 last rewards for episode 210 : -432.5424638227983 (std 276.3653918711599)\n",
      "Mean of 10 last rewards for episode 220 : -306.56279061057353 (std 211.86622259193217)\n",
      "Mean of 10 last rewards for episode 230 : -291.18617109818894 (std 219.3531494346885)\n",
      "Mean of 10 last rewards for episode 240 : -301.5585382634943 (std 201.3576682257616)\n",
      "Mean of 10 last rewards for episode 250 : -447.5537012273615 (std 201.63492934760149)\n",
      "Mean of 10 last rewards for episode 260 : -315.13445559414953 (std 254.78374957697662)\n",
      "Mean of 10 last rewards for episode 270 : -381.7397100275213 (std 205.27952486511563)\n",
      "Mean of 10 last rewards for episode 280 : -160.40288196910512 (std 119.74111850376724)\n",
      "Mean of 10 last rewards for episode 290 : -368.9906213933771 (std 218.3170652053886)\n",
      "Mean of 10 last rewards for episode 300 : -204.97761743718928 (std 172.8594960150115)\n",
      "Mean of 10 last rewards for episode 310 : -169.17079370672053 (std 101.62990065144236)\n",
      "Mean of 10 last rewards for episode 320 : -208.8836704600941 (std 151.50679341047226)\n",
      "Mean of 10 last rewards for episode 330 : -177.00911504572088 (std 149.02709620115172)\n",
      "Mean of 10 last rewards for episode 340 : -171.7768159346147 (std 142.13041439842954)\n",
      "Mean of 10 last rewards for episode 350 : -138.18880809437144 (std 64.57827881725329)\n",
      "Mean of 10 last rewards for episode 360 : -195.80004258589312 (std 179.21280065137034)\n",
      "Mean of 10 last rewards for episode 370 : -202.1069668856534 (std 111.52089936792729)\n",
      "Mean of 10 last rewards for episode 380 : -135.30357152765447 (std 119.84407453485213)\n",
      "Mean of 10 last rewards for episode 390 : -188.40952439741656 (std 148.90423152762799)\n",
      "Mean of 10 last rewards for episode 400 : -155.0991308038885 (std 130.57508773154058)\n",
      "Mean of 10 last rewards for episode 410 : -117.11143146861683 (std 60.9429238803185)\n",
      "Mean of 10 last rewards for episode 420 : -138.71987429532138 (std 47.372855186527225)\n",
      "Mean of 10 last rewards for episode 430 : -129.95564339377663 (std 47.65934483562252)\n",
      "Mean of 10 last rewards for episode 440 : -144.19542902166194 (std 66.00394976381877)\n",
      "Mean of 10 last rewards for episode 450 : -129.4736064564098 (std 51.49375584792295)\n",
      "Mean of 10 last rewards for episode 460 : -119.36313351717862 (std 54.39127727220976)\n",
      "Mean of 10 last rewards for episode 470 : -125.95168373801492 (std 70.7748199625922)\n",
      "Mean of 10 last rewards for episode 480 : -119.02284587513317 (std 66.55234674839375)\n",
      "Mean of 10 last rewards for episode 490 : -139.8399554165927 (std 51.097012743787886)\n",
      "Mean of 10 last rewards for episode 500 : -109.34600413929333 (std 42.131009346701134)\n",
      "Mean of 10 last rewards for episode 510 : -291.9350454157049 (std 207.43169638940566)\n",
      "Mean of 10 last rewards for episode 520 : -208.6265737360174 (std 219.84805131591128)\n",
      "Mean of 10 last rewards for episode 530 : -203.41126181862572 (std 199.31771149705963)\n",
      "Mean of 10 last rewards for episode 540 : -204.11111935702237 (std 195.45114534132514)\n",
      "Mean of 10 last rewards for episode 550 : -247.00133722478694 (std 162.80436842020436)\n",
      "Mean of 10 last rewards for episode 560 : -515.767988725142 (std 208.31261169267273)\n",
      "Mean of 10 last rewards for episode 570 : -295.0498553189364 (std 226.0096832080466)\n",
      "Mean of 10 last rewards for episode 580 : -189.17513968727806 (std 180.8204850295026)\n",
      "Mean of 10 last rewards for episode 590 : -229.19659423828125 (std 225.67072656474207)\n",
      "Mean of 10 last rewards for episode 600 : -124.03357488458806 (std 43.19400951542109)\n",
      "Mean of 10 last rewards for episode 610 : -123.27778764204545 (std 43.19533018300091)\n",
      "Mean of 10 last rewards for episode 620 : -122.17218849875711 (std 43.10783522342831)\n",
      "Mean of 10 last rewards for episode 630 : -114.33538610284978 (std 42.989097719643986)\n",
      "Mean of 10 last rewards for episode 640 : -152.8556144020774 (std 117.6078333389985)\n",
      "Mean of 10 last rewards for episode 650 : -179.08424100008878 (std 143.15689225601378)\n",
      "Mean of 10 last rewards for episode 660 : -170.52357482910156 (std 203.3288536603083)\n",
      "Mean of 10 last rewards for episode 670 : -255.91059251265094 (std 202.41948816622457)\n",
      "Mean of 10 last rewards for episode 680 : -211.19582158868963 (std 203.47382258292015)\n",
      "Mean of 10 last rewards for episode 690 : -449.1354883367365 (std 256.05532500377683)\n",
      "Mean of 10 last rewards for episode 700 : -297.44499761408025 (std 290.00491575289186)\n",
      "Mean of 10 last rewards for episode 710 : -234.12323067405006 (std 220.3072026776062)\n",
      "Mean of 10 last rewards for episode 720 : -180.31448364257812 (std 115.83027309470192)\n",
      "Mean of 10 last rewards for episode 730 : -267.6713464910334 (std 217.72900479459977)\n",
      "Mean of 10 last rewards for episode 740 : -425.1869694102894 (std 279.2400781126834)\n",
      "Mean of 10 last rewards for episode 750 : -443.7238804210316 (std 277.4651001420578)\n",
      "Mean of 10 last rewards for episode 760 : -210.34546453302556 (std 169.61219799839276)\n",
      "Mean of 10 last rewards for episode 770 : -235.9191499189897 (std 204.56943648525984)\n",
      "Mean of 10 last rewards for episode 780 : -264.0817038796165 (std 236.9001494394214)\n",
      "Mean of 10 last rewards for episode 790 : -379.0920895663175 (std 220.753850226001)\n",
      "Mean of 10 last rewards for episode 800 : -560.8460159301758 (std 436.85543119118296)\n",
      "Mean of 10 last rewards for episode 810 : -324.0736514004794 (std 184.50267717167898)\n",
      "Mean of 10 last rewards for episode 820 : -332.9639164317738 (std 221.72494217533816)\n",
      "Mean of 10 last rewards for episode 830 : -358.11611730402166 (std 228.65258870914053)\n",
      "Mean of 10 last rewards for episode 840 : -338.920371315696 (std 206.26242763465646)\n",
      "Mean of 10 last rewards for episode 850 : -341.5141539140181 (std 228.43365050899803)\n",
      "Mean of 10 last rewards for episode 860 : -443.48843799937856 (std 210.96825884452664)\n",
      "Mean of 10 last rewards for episode 870 : -424.80323305996984 (std 239.57229922661654)\n",
      "Mean of 10 last rewards for episode 880 : -299.25843464244497 (std 282.44271117176413)\n",
      "Mean of 10 last rewards for episode 890 : -370.6230891834606 (std 276.9702723417084)\n",
      "Mean of 10 last rewards for episode 900 : -449.0101623535156 (std 258.9274297690141)\n",
      "Mean of 10 last rewards for episode 910 : -511.7620766379616 (std 293.6445216345578)\n",
      "Mean of 10 last rewards for episode 920 : -482.8993668989702 (std 253.58321242780946)\n",
      "Mean of 10 last rewards for episode 930 : -291.19656996293503 (std 208.70233602992118)\n",
      "Mean of 10 last rewards for episode 940 : -360.66390852494675 (std 250.24367420689572)\n",
      "Mean of 10 last rewards for episode 950 : -340.99629350142044 (std 205.05478861909768)\n",
      "Mean of 10 last rewards for episode 960 : -216.90532823042437 (std 145.28514301142187)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of 10 last rewards for episode 970 : -326.65511044588953 (std 203.89327108823272)\n",
      "Mean of 10 last rewards for episode 980 : -354.6663443825462 (std 247.74135229700667)\n",
      "Mean of 10 last rewards for episode 990 : -291.7698235945268 (std 222.38492329359548)\n",
      "Mean of 10 last rewards for episode 1000 : -273.45647915926844 (std 229.53723220971182)\n"
     ]
    }
   ],
   "source": [
    "# Initialisation de l'environnement\n",
    "env_id = 'LunarLander-v2'\n",
    "SEED_ENVIRONMENT = 42\n",
    "env, envx = init_environment(env_id, seed=SEED_ENVIRONMENT)\n",
    "\n",
    "agent = A2C(dim_input=env.observation_space.shape[0],\n",
    "            dim_output=env.action_space.n,\n",
    "            gamma=0.99,\n",
    "            alpha=0.7,\n",
    "            layers=[30, 30],\n",
    "            lr_V=0.01,\n",
    "            lr_pi=0.001)\n",
    "run_agent_on_environment(agent, env, envx,\n",
    "                         max_episode=1000,\n",
    "                         iter_print=10,\n",
    "                         iter_show=100, name_file='a2c_lunarlander.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Batch A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 4\n",
      "Mean of 10 last rewards for episode 10 : -443.37635664506394 (std 218.91772012349224)\n",
      "Mean of 10 last rewards for episode 20 : -550.518349387429 (std 237.8081268301725)\n",
      "Mean of 10 last rewards for episode 30 : -543.5897438742898 (std 215.96027177761067)\n",
      "Mean of 10 last rewards for episode 40 : -520.0400945490056 (std 260.1357025517608)\n",
      "Mean of 10 last rewards for episode 50 : -587.2592329545455 (std 300.7694502696428)\n",
      "Mean of 10 last rewards for episode 60 : -552.4935385964134 (std 224.93019392376536)\n",
      "Mean of 10 last rewards for episode 70 : -567.5935890891335 (std 230.2363881511052)\n",
      "Mean of 10 last rewards for episode 80 : -459.8474148837003 (std 224.95765631572644)\n",
      "Mean of 10 last rewards for episode 90 : -602.0666170987216 (std 300.2314419911113)\n",
      "Mean of 10 last rewards for episode 100 : -540.9567232998935 (std 245.33043529032628)\n",
      "Mean of 10 last rewards for episode 110 : -477.47955599698156 (std 201.72422897444457)\n",
      "Mean of 10 last rewards for episode 120 : -565.2390830300071 (std 284.958045891235)\n",
      "Mean of 10 last rewards for episode 130 : -486.36888261274856 (std 197.8751581852203)\n",
      "Mean of 10 last rewards for episode 140 : -515.4293379350142 (std 224.90634803083427)\n",
      "Mean of 10 last rewards for episode 150 : -544.7078080610795 (std 251.16797356735222)\n",
      "Mean of 10 last rewards for episode 160 : -490.5787880637429 (std 244.785382939638)\n",
      "Mean of 10 last rewards for episode 170 : -516.367129239169 (std 209.53879051702626)\n",
      "Mean of 10 last rewards for episode 180 : -460.3359541459517 (std 202.4732872567585)\n",
      "Mean of 10 last rewards for episode 190 : -542.2058854536576 (std 225.9735292408691)\n",
      "Mean of 10 last rewards for episode 200 : -604.065410267223 (std 259.8634238012135)\n",
      "Mean of 10 last rewards for episode 210 : -537.7345664284446 (std 226.03810880550847)\n",
      "Mean of 10 last rewards for episode 220 : -432.4929282448509 (std 155.56771460749312)\n",
      "Mean of 10 last rewards for episode 230 : -488.3258528275923 (std 219.61879382692615)\n",
      "Mean of 10 last rewards for episode 240 : -603.4751059792259 (std 270.8569829064341)\n",
      "Mean of 10 last rewards for episode 250 : -660.1474054509944 (std 292.35124015729195)\n",
      "Mean of 10 last rewards for episode 260 : -540.3473593971946 (std 203.61036508989102)\n",
      "Mean of 10 last rewards for episode 270 : -568.6196705211293 (std 267.8240976119933)\n",
      "Mean of 10 last rewards for episode 280 : -504.60921963778407 (std 232.3064971670486)\n",
      "Mean of 10 last rewards for episode 290 : -550.4699346368963 (std 227.76202825343552)\n",
      "Mean of 10 last rewards for episode 300 : -530.6243424849076 (std 280.74458830012514)\n",
      "Mean of 10 last rewards for episode 310 : -438.2896839488636 (std 177.48859223677067)\n",
      "Mean of 10 last rewards for episode 320 : -490.460673939098 (std 225.1495835997424)\n",
      "Mean of 10 last rewards for episode 330 : -416.1859408291903 (std 142.55978139603022)\n",
      "Mean of 10 last rewards for episode 340 : -498.29994062943894 (std 189.2409305133346)\n",
      "Mean of 10 last rewards for episode 350 : -455.71879438920456 (std 193.03069954736765)\n",
      "Mean of 10 last rewards for episode 360 : -470.5878184925426 (std 191.9901554856435)\n",
      "Mean of 10 last rewards for episode 370 : -555.2220569957386 (std 254.34928485348473)\n",
      "Mean of 10 last rewards for episode 380 : -602.9484585848721 (std 249.76573754961518)\n",
      "Mean of 10 last rewards for episode 390 : -457.1636657714844 (std 198.91278565651461)\n",
      "Mean of 10 last rewards for episode 400 : -514.4601301713424 (std 236.50986401110785)\n",
      "Mean of 10 last rewards for episode 410 : -604.9209483753551 (std 245.77244156697193)\n",
      "Mean of 10 last rewards for episode 420 : -514.5315940163352 (std 235.98532526977598)\n",
      "Mean of 10 last rewards for episode 430 : -512.8273592862216 (std 215.71733462585226)\n",
      "Mean of 10 last rewards for episode 440 : -531.614501953125 (std 249.29910745938486)\n",
      "Mean of 10 last rewards for episode 450 : -455.5468583540483 (std 198.17056351212457)\n",
      "Mean of 10 last rewards for episode 460 : -565.5919272682884 (std 290.30086638754267)\n",
      "Mean of 10 last rewards for episode 470 : -551.5042946555398 (std 299.2492921957437)\n",
      "Mean of 10 last rewards for episode 480 : -529.3557212136009 (std 234.68876297603927)\n",
      "Mean of 10 last rewards for episode 490 : -554.4020330255681 (std 283.5060881089291)\n",
      "Mean of 10 last rewards for episode 500 : -556.8417691317471 (std 287.6576426431756)\n",
      "Mean of 10 last rewards for episode 510 : -555.3916376287287 (std 239.57649153425493)\n",
      "Mean of 10 last rewards for episode 520 : -486.8900257457386 (std 191.0271406619913)\n",
      "Mean of 10 last rewards for episode 530 : -603.5221751819957 (std 236.14222912715516)\n",
      "Mean of 10 last rewards for episode 540 : -566.057822487571 (std 267.29728278436147)\n",
      "Mean of 10 last rewards for episode 550 : -492.197978626598 (std 246.74620054104685)\n",
      "Mean of 10 last rewards for episode 560 : -522.0273465243253 (std 222.4932200470295)\n",
      "Mean of 10 last rewards for episode 570 : -497.5747902610085 (std 228.80425320767512)\n",
      "Mean of 10 last rewards for episode 580 : -539.9931113503196 (std 250.0013117988454)\n",
      "Mean of 10 last rewards for episode 590 : -480.82924582741475 (std 202.56591160362723)\n",
      "Mean of 10 last rewards for episode 600 : -467.62525801225144 (std 211.0320225671605)\n",
      "Mean of 10 last rewards for episode 610 : -541.0692998712713 (std 269.6198422986421)\n",
      "Mean of 10 last rewards for episode 620 : -613.5264753861861 (std 277.2180732870283)\n",
      "Mean of 10 last rewards for episode 630 : -470.3351551402699 (std 212.1634309422342)\n",
      "Mean of 10 last rewards for episode 640 : -644.4082724831321 (std 243.69540553272847)\n",
      "Mean of 10 last rewards for episode 650 : -455.3936379172585 (std 175.2534988791537)\n",
      "Mean of 10 last rewards for episode 660 : -463.331279407848 (std 186.35245129331707)\n",
      "Mean of 10 last rewards for episode 670 : -507.73407259854406 (std 232.71391033403347)\n",
      "Mean of 10 last rewards for episode 680 : -518.6414295543324 (std 206.46646126959274)\n",
      "Mean of 10 last rewards for episode 690 : -514.2630559747869 (std 234.90447695755861)\n",
      "Mean of 10 last rewards for episode 700 : -513.6553733132102 (std 259.1059901368558)\n",
      "Mean of 10 last rewards for episode 710 : -562.9989402077415 (std 220.3183737559109)\n",
      "Mean of 10 last rewards for episode 720 : -473.1431884765625 (std 191.2965473001827)\n",
      "Mean of 10 last rewards for episode 730 : -538.4572726162997 (std 239.6590179819197)\n",
      "Mean of 10 last rewards for episode 740 : -511.64851795543325 (std 233.32719852266368)\n",
      "Mean of 10 last rewards for episode 750 : -668.6810996315696 (std 268.14174900358034)\n",
      "Mean of 10 last rewards for episode 760 : -486.7880359996449 (std 222.49032794538863)\n",
      "Mean of 10 last rewards for episode 770 : -577.038818359375 (std 282.45214715596796)\n",
      "Mean of 10 last rewards for episode 780 : -503.7432833584872 (std 236.16142947352677)\n",
      "Mean of 10 last rewards for episode 790 : -571.4058449485085 (std 270.13274190511436)\n",
      "Mean of 10 last rewards for episode 800 : -508.72214577414775 (std 221.60429956399324)\n",
      "Mean of 10 last rewards for episode 810 : -543.4502646706321 (std 236.12805031705474)\n",
      "Mean of 10 last rewards for episode 820 : -550.3077891956676 (std 254.54516466181747)\n",
      "Mean of 10 last rewards for episode 830 : -520.831934148615 (std 235.71208847414977)\n",
      "Mean of 10 last rewards for episode 840 : -559.9300231933594 (std 233.09567790482802)\n",
      "Mean of 10 last rewards for episode 850 : -401.75743241743606 (std 146.5199992455247)\n",
      "Mean of 10 last rewards for episode 860 : -535.886288729581 (std 239.5712103717592)\n",
      "Mean of 10 last rewards for episode 870 : -501.4658952192827 (std 207.82375848701176)\n",
      "Mean of 10 last rewards for episode 880 : -483.9315185546875 (std 181.43651605731625)\n",
      "Mean of 10 last rewards for episode 890 : -469.70782470703125 (std 206.32409965070516)\n",
      "Mean of 10 last rewards for episode 900 : -566.9618419300426 (std 262.10902550684693)\n",
      "Mean of 10 last rewards for episode 910 : -526.437050559304 (std 231.91834875729114)\n",
      "Mean of 10 last rewards for episode 920 : -524.4584822221236 (std 224.44779634026517)\n",
      "Mean of 10 last rewards for episode 930 : -480.02058549360794 (std 201.339389825459)\n",
      "Mean of 10 last rewards for episode 940 : -494.0997314453125 (std 239.5560113805022)\n",
      "Mean of 10 last rewards for episode 950 : -568.6346574263139 (std 236.7687983030922)\n",
      "Mean of 10 last rewards for episode 960 : -542.5252158425071 (std 226.68574268558592)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of 10 last rewards for episode 970 : -512.4780162464489 (std 229.8054231945858)\n",
      "Mean of 10 last rewards for episode 980 : -447.5838068181818 (std 183.64975887590433)\n",
      "Mean of 10 last rewards for episode 990 : -508.3662802956321 (std 263.6336368550151)\n",
      "Mean of 10 last rewards for episode 1000 : -513.886191628196 (std 271.08494848390865)\n"
     ]
    }
   ],
   "source": [
    "# Initialisation de l'environnement\n",
    "env_id = 'LunarLander-v2'\n",
    "SEED_ENVIRONMENT = 42\n",
    "env, envx = init_environment(env_id, seed=SEED_ENVIRONMENT)\n",
    "print(env.observation_space.shape[0], env.action_space.n)\n",
    "agent = A2CBatch(dim_input=env.observation_space.shape[0],\n",
    "            dim_output=env.action_space.n,\n",
    "            gamma=0.99,\n",
    "            alpha=0.7,\n",
    "            layers=[30, 30],\n",
    "            lr_V=0.01,\n",
    "            lr_pi=0.001)\n",
    "run_agent_on_environment(agent, env, envx,\n",
    "                         max_episode=1000,\n",
    "                         iter_print=10,\n",
    "                         iter_show=100, \n",
    "                         name_file='a2c_batch_lunarlander.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
